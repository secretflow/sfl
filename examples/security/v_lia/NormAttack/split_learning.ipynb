{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuyM4I2f-FrW"
   },
   "source": [
    "# Split Learning and Label Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "sf.init([\"client\", \"server\"], address=\"local\")\n",
    "client, server = sf.PYU(\"client\"), sf.PYU(\"server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48I_xRo9-Hez"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from attack.labelleakage import NormAttackSplitNNManager\n",
    "from collaborative.splitnn import SplitNNAPI, SplitNNClient\n",
    "from utils.utils import NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def zero_activation(x):\n",
    "    return tf.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6HcMly6_Yq9"
   },
   "outputs": [],
   "source": [
    "def create_first_net(input_dim, hidden_dim, name=\"first_net\"):\n",
    "    # Create model\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_dim),\n",
    "                layers.Dense(hidden_dim // 2, activation=\"relu\"),\n",
    "                layers.Dense(hidden_dim, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        learning_rate = 1e-3  # 设置学习率\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\"accuracy\", tf.keras.metrics.AUC()],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return create_model\n",
    "\n",
    "\n",
    "def create_zero_net(input_dim, hidden_dim, name=\"zero_net\"):\n",
    "    # Create model\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_dim),\n",
    "                layers.Dense(hidden_dim, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        learning_rate = 1e-3  # 设置学习率\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\"accuracy\", tf.keras.metrics.AUC()],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fuse_model(\n",
    "    input_dim_1, input_dim_2, output_dim, party_nums, name=\"fuse_model\"\n",
    "):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "\n",
    "        # input\n",
    "        input_layers = []\n",
    "        # for i in range(party_nums):\n",
    "        input_layers.append(\n",
    "            keras.Input(\n",
    "                input_dim_1,\n",
    "            )\n",
    "        )\n",
    "        input_layers.append(\n",
    "            keras.Input(\n",
    "                input_dim_2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        merged_layer = layers.concatenate(input_layers)\n",
    "        output = layers.Dense(output_dim, activation=\"sigmoid\")(merged_layer)\n",
    "        # output = layers.Dense(output_dim, activation='relu')(fuse_layer)\n",
    "\n",
    "        model = keras.Model(inputs=input_layers, outputs=output)\n",
    "        model.summary()\n",
    "\n",
    "        learning_rate = 1e-3  # 设置学习率\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\"accuracy\", tf.keras.metrics.AUC()],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3jrDrel_zsO"
   },
   "source": [
    "## Parameters and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "\n",
    "raw_df = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
    ")\n",
    "raw_df_neg = raw_df[raw_df[\"Class\"] == 0]\n",
    "raw_df_pos = raw_df[raw_df[\"Class\"] == 1]\n",
    "\n",
    "down_df_neg = raw_df_neg  # .sample(40000)\n",
    "down_df = pd.concat([down_df_neg, raw_df_pos])\n",
    "\n",
    "neg, pos = np.bincount(down_df[\"Class\"])\n",
    "total = neg + pos\n",
    "print(\n",
    "    \"Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n\".format(\n",
    "        total, pos, 100 * pos / total\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = down_df.copy()\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop(\"Time\")\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001  # 0 => 0.1¢\n",
    "cleaned_df[\"Log Ammount\"] = np.log(cleaned_df.pop(\"Amount\") + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data_index = [\n",
    "    col\n",
    "    for col in cleaned_df.columns\n",
    "    if col != \"Class\" and col != \"V1\" and col != \"V2\" and col != \"V3\" and col != \"V4\"\n",
    "]\n",
    "client_data = cleaned_df[client_data_index]\n",
    "client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_data = cleaned_df[[\"V1\", \"V2\", \"V3\", \"V4\", \"Class\"]]\n",
    "server_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([client_data, server_data], axis=1)\n",
    "df = df[-284160:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.data.split import train_test_split\n",
    "from sfl.ml.nn import SLModel\n",
    "\n",
    "spu = sf.SPU(sf.utils.testing.cluster_def([\"client\", \"server\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.utils.simulation.data.dataframe import create_df\n",
    "\n",
    "data = create_df(\n",
    "    source=df,\n",
    "    parts={client: (0, 25), server: (25, 29)},\n",
    "    axis=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "label = create_df(\n",
    "    source=df,\n",
    "    parts={server: (29, 30)},\n",
    "    axis=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"label= {type(label)},\\ndata = {type(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认VDataFrame存储无误\n",
    "# print(data.to_csv({server: \"server\"}))\n",
    "# print(data.to_csv({client: \"client\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.preprocessing.scaler import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "# data = data.clip(-5,5)  # 由于sf中没有实现clip函数，因此先注释掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "train_data, test_data = train_test_split(\n",
    "    data, train_size=0.8, random_state=random_state\n",
    ")\n",
    "train_label, test_label = train_test_split(\n",
    "    label, train_size=0.8, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bopA4CdS_4-T"
   },
   "source": [
    "## Split Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim_1 = 28\n",
    "hidden_dim_2 = 4\n",
    "# Create FirstNet model\n",
    "client_builder = create_first_net(input_dim=25, hidden_dim=hidden_dim_1)\n",
    "# client_model = first_net_builder()\n",
    "\n",
    "# Create ZeroNet model\n",
    "server_zero_builder = create_zero_net(input_dim=4, hidden_dim=hidden_dim_2)\n",
    "# server_zero_model = zero_net_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_builder = create_fuse_model(\n",
    "    input_dim_1=hidden_dim_1, input_dim_2=hidden_dim_2, party_nums=2, output_dim=1\n",
    ")\n",
    "# fuse_net_model = fuse_net_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dict = {client: client_builder, server: server_zero_builder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加DP模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfl.security.privacy import DPStrategy, LabelDP\n",
    "from sfl.security.privacy.mechanism.tensorflow import GaussianEmbeddingDP\n",
    "\n",
    "# Define DP operations\n",
    "train_batch_size = 1024\n",
    "gaussian_embedding_dp = GaussianEmbeddingDP(\n",
    "    noise_multiplier=0.5,\n",
    "    l2_norm_clip=1.0,\n",
    "    batch_size=train_batch_size,\n",
    "    num_samples=train_data.values.partition_shape()[server][0],\n",
    "    is_secure_generator=False,\n",
    ")\n",
    "label_dp = LabelDP(eps=64.0)\n",
    "dp_strategy_server = DPStrategy(label_dp=label_dp)\n",
    "dp_strategy_client = DPStrategy(embedding_dp=gaussian_embedding_dp)\n",
    "dp_strategy_dict = {client: dp_strategy_client, server: dp_strategy_server}\n",
    "dp_spent_step_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict, device_y=server, model_fuse=fuse_builder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练SplitNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack.labelleakage import NormAttackSplitNNManager_sf\n",
    "\n",
    "manager = NormAttackSplitNNManager_sf(device=\"cpu\")\n",
    "NormAttackSplitNNAPI = manager.attach(SLModel)\n",
    "normattacksplitnn = NormAttackSplitNNAPI(\n",
    "    base_model_dict=base_model_dict, device_y=server, model_fuse=fuse_builder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 1024\n",
    "epochs = 10\n",
    "history = normattacksplitnn.fit(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    validation_data=(test_data, test_label),\n",
    "    epochs=epochs,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_freq=1,\n",
    "    dp_spent_step_freq=dp_spent_step_freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估SplitNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change of loss during training\n",
    "plt.plot(history[\"train_loss\"])\n",
    "plt.plot(history[\"val_loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change of accuracy during training\n",
    "plt.plot(history[\"train_accuracy\"])\n",
    "plt.plot(history[\"val_accuracy\"])\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Area Under Curve(AUC) of loss during training\n",
    "plt.plot(history[\"train_auc_1\"])\n",
    "plt.plot(history[\"val_auc_1\"])\n",
    "plt.title(\"Model Area Under Curve\")\n",
    "plt.ylabel(\"Area Under Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm Attack实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_norms = normattacksplitnn.attack_grad(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    validation_data=(test_data, test_label),\n",
    "    epochs=epochs,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_freq=1,\n",
    ")\n",
    "# dp_spent_step_freq=dp_spent_step_freq,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm Attack评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# jnp.sum(g_norms,axis=1)\n",
    "normattack_pred = jnp.concatenate(g_norms)\n",
    "normattack_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "ground_label = sf.reveal(train_label.values.partitions[server])\n",
    "ground_label = ground_label.flatten()\n",
    "ground_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 JAX 数组转换为 NumPy 数组\n",
    "y_true_numpy = ground_label.tolist()\n",
    "y_pred_numpy = normattack_pred.tolist()\n",
    "\n",
    "# 计算 ROC-AUC\n",
    "roc_auc = roc_auc_score(y_true_numpy, y_pred_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "secretflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
